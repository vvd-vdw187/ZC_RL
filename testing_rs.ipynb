{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy-ul8eqpkm9",
        "outputId": "e4349521-51fd-4644-c9ba-c7cca9fa3a86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'ZC_RL'...\n",
            "remote: Enumerating objects: 96, done.\u001b[K\n",
            "remote: Counting objects: 100% (96/96), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 96 (delta 54), reused 68 (delta 26), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (96/96), 77.12 KiB | 7.01 MiB/s, done.\n",
            "Resolving deltas: 100% (54/54), done.\n",
            "Requirement already satisfied: gym[atari]==0.26.2 in /usr/local/lib/python3.10/dist-packages (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[atari]==0.26.2) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[atari]==0.26.2) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[atari]==0.26.2) (0.0.8)\n",
            "Requirement already satisfied: ale-py~=0.8.0 in /usr/local/lib/python3.10/dist-packages (from gym[atari]==0.26.2) (0.8.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.0->gym[atari]==0.26.2) (6.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.0->gym[atari]==0.26.2) (4.5.0)\n",
            "Requirement already satisfied: autorom[accept-rom-license]==0.6.1 in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]==0.6.1) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]==0.6.1) (2.31.0)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]==0.6.1) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]==0.6.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]==0.6.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]==0.6.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]==0.6.1) (2023.11.17)\n",
            "Cloning into 'ZC_RL'...\n",
            "remote: Enumerating objects: 96, done.\u001b[K\n",
            "remote: Counting objects: 100% (96/96), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 96 (delta 54), reused 68 (delta 26), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (96/96), 77.12 KiB | 19.28 MiB/s, done.\n",
            "Resolving deltas: 100% (54/54), done.\n",
            "Requirement already satisfied: gym[atari]==0.26.2 in /usr/local/lib/python3.10/dist-packages (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[atari]==0.26.2) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[atari]==0.26.2) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[atari]==0.26.2) (0.0.8)\n",
            "Requirement already satisfied: ale-py~=0.8.0 in /usr/local/lib/python3.10/dist-packages (from gym[atari]==0.26.2) (0.8.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.0->gym[atari]==0.26.2) (6.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.0->gym[atari]==0.26.2) (4.5.0)\n",
            "Requirement already satisfied: autorom[accept-rom-license]==0.6.1 in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]==0.6.1) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]==0.6.1) (2.31.0)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]==0.6.1) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]==0.6.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]==0.6.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]==0.6.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]==0.6.1) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "!rm -rf ZC_RL  # This removes any existing directory named ZC_RL\n",
        "!git clone https://github.com/vvd-vdw187/ZC_RL.git\n",
        "!pip install gym[atari]==0.26.2\n",
        "!pip install autorom[accept-rom-license]==0.6.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1Nwo7Qzpty9"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"ZC_RL/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8FyelBqpj3Y"
      },
      "outputs": [],
      "source": [
        "from random_search import RandomSearch\n",
        "import gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCaZ-hgZpj3a",
        "outputId": "3f9dc5bb-cc92-43b3-e569-bc020714c7ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'None', 1: <function conv1x1 at 0x7f8c4de46200>, 2: <function conv1x1_bn at 0x7f8b932dba30>, 3: <function conv1x1_bn_relu at 0x7f8b932dbb50>, 4: <function conv1x1_relu at 0x7f8b932dbc70>, 5: <function conv3x3 at 0x7f8c4cfc6440>, 6: <function conv3x3_bn at 0x7f8b932dbac0>, 7: <function conv3x3_bn_relu at 0x7f8b932dbbe0>, 8: <function conv3x3_relu at 0x7f8b932dbd00>}\n",
            "full model:  Sequential(\n",
            "  (1): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (2): Flatten(start_dim=1, end_dim=-1)\n",
            "  (3): Linear(in_features=2150400, out_features=3, bias=True)\n",
            "  (4): ReLU()\n",
            ")\n",
            "Post init:\n",
            "--------------------------------------------------------------------------------\n",
            "DQN:\n",
            "lr: 0.0001\n",
            "optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "epsilon: 1.0\n",
            "epsilon_decay: 0.01\n",
            "epsilon_min: 0.0\n",
            "mean loss: nan\n",
            "mean reward: nan\n",
            "Model: Sequential(\n",
            "  (1): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (2): Flatten(start_dim=1, end_dim=-1)\n",
            "  (3): Linear(in_features=2150400, out_features=3, bias=True)\n",
            "  (4): ReLU()\n",
            ")\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([32, 32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode: 0, reward: 0.0.\n",
            "model  0  trained:\n",
            "reward:  0.0\n",
            "losses:  nan\n",
            "pool:  [(0.0, nan, Sequential(\n",
            "  (1): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (2): Flatten(start_dim=1, end_dim=-1)\n",
            "  (3): Linear(in_features=2150400, out_features=3, bias=True)\n",
            "  (4): ReLU()\n",
            "))]\n"
          ]
        }
      ],
      "source": [
        "num_models = 1\n",
        "train_iterations = 1\n",
        "\n",
        "env = gym.make('Freeway-v4')\n",
        "RS = RandomSearch(env)\n",
        "RS.search(max_models=num_models, train_iterations=train_iterations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "ZO5LkEEKqpaF",
        "outputId": "30190509-5948-4145-a963-68c4887998bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'None', 1: <function conv1x1 at 0x7a2740de9990>, 2: <function conv1x1_bn at 0x7a268699c5e0>, 3: <function conv1x1_bn_relu at 0x7a268699c700>, 4: <function conv1x1_relu at 0x7a268699c820>, 5: <function conv3x3 at 0x7a2740de96c0>, 6: <function conv3x3_bn at 0x7a268699c670>, 7: <function conv3x3_bn_relu at 0x7a268699c790>, 8: <function conv3x3_relu at 0x7a268699c8b0>}\n",
            "full model:  Sequential(\n",
            "  (1): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (2): Flatten(start_dim=1, end_dim=-1)\n",
            "  (3): Linear(in_features=537600, out_features=3, bias=True)\n",
            "  (4): ReLU()\n",
            ")\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-fae45122b6fa>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Freeway-v4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mRS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mRS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_models\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/ZC_RL/random_search.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, max_models, zero_cost_warmup, train_iterations)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_arch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mdqn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay_and_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ZC_RL/DQN.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, env, lr, optimizer, update_target_model_every, init_buffer_percentage, discount_factor, epsilon, epsilon_decay, epsilon_min, losses, train_rewards, val_rewards, replay_buffer)\u001b[0m\n",
            "\u001b[0;32m/content/ZC_RL/DQN.py\u001b[0m in \u001b[0;36m__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Adam\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Optimizer {self.optimizer} not implemented.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     43\u001b[0m                         \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforeach\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforeach\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapturable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcapturable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                         differentiable=differentiable, fused=fused)\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_param_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;31m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mallowed_functions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_backends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconvert_frame\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m from .decorators import (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mtransform_code_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m )\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0meval_frame\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0malways_optimize_code_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTorchPatcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m from .exc import (\n\u001b[1;32m     36\u001b[0m     \u001b[0maugment_exc_message\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexternal_utils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCondOpArgsMismatchError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResetRequired\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUserError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUserErrorType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmutation_guard\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minstall_generation_tagging_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/skipfiles.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inductor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_operators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content_store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "num_models = 4\n",
        "train_iterations = 3000\n",
        "\n",
        "env = gym.make('Freeway-v4')\n",
        "RS = RandomSearch(env)\n",
        "RS.search(max_models=num_models, train_iterations=train_iterations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeAEAmau7oJO",
        "outputId": "f579fbc2-ff34-473a-a2f3-234a2df2ee24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'None', 1: <function conv1x1 at 0x7987ddc0a560>, 2: <function conv1x1_bn at 0x7987235d4790>, 3: <function conv1x1_bn_relu at 0x7987235d48b0>, 4: <function conv1x1_relu at 0x7987235d49d0>, 5: <function conv3x3 at 0x7987ddc0a4d0>, 6: <function conv3x3_bn at 0x7987235d4820>, 7: <function conv3x3_bn_relu at 0x7987235d4940>, 8: <function conv3x3_relu at 0x7987235d4a60>}\n",
            "full model:  Sequential(\n",
            "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (2): Sequential(\n",
            "    (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (4): Flatten(start_dim=1, end_dim=-1)\n",
            "  (5): Linear(in_features=1075200, out_features=3, bias=True)\n",
            "  (6): ReLU()\n",
            ")\n",
            "Post init:\n",
            "--------------------------------------------------------------------------------\n",
            "DQN:\n",
            "lr: 0.0001\n",
            "optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "epsilon: 1.0\n",
            "epsilon_decay: 0.01\n",
            "epsilon_min: 0.0\n",
            "mean loss: nan\n",
            "mean train reward: nan\n",
            "mean val reward: nan\n",
            "Model: Sequential(\n",
            "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (2): Sequential(\n",
            "    (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (4): Flatten(start_dim=1, end_dim=-1)\n",
            "  (5): Linear(in_features=1075200, out_features=3, bias=True)\n",
            "  (6): ReLU()\n",
            ")\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64, 64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([32, 32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "model  5  trained:\n",
            "train reward:  0.0\n",
            "val reward:  0.0\n",
            "full model:  Sequential(\n",
            "  (0): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (3): Sequential(\n",
            "    (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (4): Flatten(start_dim=1, end_dim=-1)\n",
            "  (5): Linear(in_features=537600, out_features=3, bias=True)\n",
            "  (6): ReLU()\n",
            ")\n",
            "Post init:\n",
            "--------------------------------------------------------------------------------\n",
            "DQN:\n",
            "lr: 0.0001\n",
            "optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "epsilon: 1.0\n",
            "epsilon_decay: 0.01\n",
            "epsilon_min: 0.0\n",
            "mean loss: nan\n",
            "mean train reward: nan\n",
            "mean val reward: nan\n",
            "Model: Sequential(\n",
            "  (0): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (3): Sequential(\n",
            "    (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (4): Flatten(start_dim=1, end_dim=-1)\n",
            "  (5): Linear(in_features=537600, out_features=3, bias=True)\n",
            "  (6): ReLU()\n",
            ")\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "model  5  trained:\n",
            "train reward:  0.0\n",
            "val reward:  0.0\n",
            "full model:  Sequential(\n",
            "  (0): Conv2d(3, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (1): Conv2d(24, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (2): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (3): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (4): Flatten(start_dim=1, end_dim=-1)\n",
            "  (5): Linear(in_features=537600, out_features=3, bias=True)\n",
            "  (6): ReLU()\n",
            ")\n",
            "Post init:\n",
            "--------------------------------------------------------------------------------\n",
            "DQN:\n",
            "lr: 0.0001\n",
            "optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "epsilon: 1.0\n",
            "epsilon_decay: 0.01\n",
            "epsilon_min: 0.0\n",
            "mean loss: nan\n",
            "mean train reward: nan\n",
            "mean val reward: nan\n",
            "Model: Sequential(\n",
            "  (0): Conv2d(3, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (1): Conv2d(24, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (2): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (3): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (4): Flatten(start_dim=1, end_dim=-1)\n",
            "  (5): Linear(in_features=537600, out_features=3, bias=True)\n",
            "  (6): ReLU()\n",
            ")\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "model  5  trained:\n",
            "train reward:  0.0\n",
            "val reward:  0.0\n",
            "full model:  Sequential(\n",
            "  (0): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (1): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(24, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (3): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (4): Flatten(start_dim=1, end_dim=-1)\n",
            "  (5): Linear(in_features=1075200, out_features=3, bias=True)\n",
            "  (6): ReLU()\n",
            ")\n",
            "Post init:\n",
            "--------------------------------------------------------------------------------\n",
            "DQN:\n",
            "lr: 0.0001\n",
            "optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "epsilon: 1.0\n",
            "epsilon_decay: 0.01\n",
            "epsilon_min: 0.0\n",
            "mean loss: nan\n",
            "mean train reward: nan\n",
            "mean val reward: nan\n",
            "Model: Sequential(\n",
            "  (0): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (1): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(24, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (3): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (4): Flatten(start_dim=1, end_dim=-1)\n",
            "  (5): Linear(in_features=1075200, out_features=3, bias=True)\n",
            "  (6): ReLU()\n",
            ")\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "model  5  trained:\n",
            "train reward:  0.0\n",
            "val reward:  0.0\n",
            "full model:  Sequential(\n",
            "  (0): Sequential(\n",
            "    (0): Conv2d(3, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (1): Sequential(\n",
            "    (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (3): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (4): Flatten(start_dim=1, end_dim=-1)\n",
            "  (5): Linear(in_features=1075200, out_features=3, bias=True)\n",
            "  (6): ReLU()\n",
            ")\n",
            "Post init:\n",
            "--------------------------------------------------------------------------------\n",
            "DQN:\n",
            "lr: 0.0001\n",
            "optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "epsilon: 1.0\n",
            "epsilon_decay: 0.01\n",
            "epsilon_min: 0.0\n",
            "mean loss: nan\n",
            "mean train reward: nan\n",
            "mean val reward: nan\n",
            "Model: Sequential(\n",
            "  (0): Sequential(\n",
            "    (0): Conv2d(3, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (1): Sequential(\n",
            "    (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (3): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (4): Flatten(start_dim=1, end_dim=-1)\n",
            "  (5): Linear(in_features=1075200, out_features=3, bias=True)\n",
            "  (6): ReLU()\n",
            ")\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "model  5  trained:\n",
            "train reward:  0.0\n",
            "val reward:  0.0\n",
            "full model:  Sequential(\n",
            "  (1): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (3): Sequential(\n",
            "    (0): Conv2d(32, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (4): Flatten(start_dim=1, end_dim=-1)\n",
            "  (5): Linear(in_features=806400, out_features=3, bias=True)\n",
            "  (6): ReLU()\n",
            ")\n",
            "Post init:\n",
            "--------------------------------------------------------------------------------\n",
            "DQN:\n",
            "lr: 0.0001\n",
            "optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "epsilon: 1.0\n",
            "epsilon_decay: 0.01\n",
            "epsilon_min: 0.0\n",
            "mean loss: nan\n",
            "mean train reward: nan\n",
            "mean val reward: nan\n",
            "Model: Sequential(\n",
            "  (1): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (3): Sequential(\n",
            "    (0): Conv2d(32, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (4): Flatten(start_dim=1, end_dim=-1)\n",
            "  (5): Linear(in_features=806400, out_features=3, bias=True)\n",
            "  (6): ReLU()\n",
            ")\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "model  4  trained:\n",
            "train reward:  0.0\n",
            "val reward:  0.0\n",
            "full model:  Sequential(\n",
            "  (0): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (1): Sequential(\n",
            "    (0): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (3): Sequential(\n",
            "    (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (4): Flatten(start_dim=1, end_dim=-1)\n",
            "  (5): Linear(in_features=806400, out_features=3, bias=True)\n",
            "  (6): ReLU()\n",
            ")\n",
            "Post init:\n",
            "--------------------------------------------------------------------------------\n",
            "DQN:\n",
            "lr: 0.0001\n",
            "optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "epsilon: 1.0\n",
            "epsilon_decay: 0.01\n",
            "epsilon_min: 0.0\n",
            "mean loss: nan\n",
            "mean train reward: nan\n",
            "mean val reward: nan\n",
            "Model: Sequential(\n",
            "  (0): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (1): Sequential(\n",
            "    (0): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (3): Sequential(\n",
            "    (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (4): Flatten(start_dim=1, end_dim=-1)\n",
            "  (5): Linear(in_features=806400, out_features=3, bias=True)\n",
            "  (6): ReLU()\n",
            ")\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "model  5  trained:\n",
            "train reward:  0.0\n",
            "val reward:  0.0\n",
            "full model:  Sequential(\n",
            "  (1): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (0): Conv2d(32, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (3): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (4): Flatten(start_dim=1, end_dim=-1)\n",
            "  (5): Linear(in_features=2150400, out_features=3, bias=True)\n",
            "  (6): ReLU()\n",
            ")\n",
            "Post init:\n",
            "--------------------------------------------------------------------------------\n",
            "DQN:\n",
            "lr: 0.0001\n",
            "optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "epsilon: 1.0\n",
            "epsilon_decay: 0.01\n",
            "epsilon_min: 0.0\n",
            "mean loss: nan\n",
            "mean train reward: nan\n",
            "mean val reward: nan\n",
            "Model: Sequential(\n",
            "  (1): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (0): Conv2d(32, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (3): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (4): Flatten(start_dim=1, end_dim=-1)\n",
            "  (5): Linear(in_features=2150400, out_features=3, bias=True)\n",
            "  (6): ReLU()\n",
            ")\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "model  4  trained:\n",
            "train reward:  0.0\n",
            "val reward:  0.0\n",
            "full model:  Sequential(\n",
            "  (0): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (3): Sequential(\n",
            "    (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (4): Flatten(start_dim=1, end_dim=-1)\n",
            "  (5): Linear(in_features=537600, out_features=3, bias=True)\n",
            "  (6): ReLU()\n",
            ")\n",
            "Post init:\n",
            "--------------------------------------------------------------------------------\n",
            "DQN:\n",
            "lr: 0.0001\n",
            "optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "epsilon: 1.0\n",
            "epsilon_decay: 0.01\n",
            "epsilon_min: 0.0\n",
            "mean loss: nan\n",
            "mean train reward: nan\n",
            "mean val reward: nan\n",
            "Model: Sequential(\n",
            "  (0): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (3): Sequential(\n",
            "    (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (4): Flatten(start_dim=1, end_dim=-1)\n",
            "  (5): Linear(in_features=537600, out_features=3, bias=True)\n",
            "  (6): ReLU()\n",
            ")\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "model  4  trained:\n",
            "train reward:  0.0\n",
            "val reward:  0.0\n",
            "full model:  Sequential(\n",
            "  (0): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (3): Sequential(\n",
            "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (4): Flatten(start_dim=1, end_dim=-1)\n",
            "  (5): Linear(in_features=1075200, out_features=3, bias=True)\n",
            "  (6): ReLU()\n",
            ")\n",
            "Post init:\n",
            "--------------------------------------------------------------------------------\n",
            "DQN:\n",
            "lr: 0.0001\n",
            "optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "epsilon: 1.0\n",
            "epsilon_decay: 0.01\n",
            "epsilon_min: 0.0\n",
            "mean loss: nan\n",
            "mean train reward: nan\n",
            "mean val reward: nan\n",
            "Model: Sequential(\n",
            "  (0): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (3): Sequential(\n",
            "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (4): Flatten(start_dim=1, end_dim=-1)\n",
            "  (5): Linear(in_features=1075200, out_features=3, bias=True)\n",
            "  (6): ReLU()\n",
            ")\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "model  4  trained:\n",
            "train reward:  0.0\n",
            "val reward:  0.0\n",
            "pool:  []\n",
            "zero cost pool:  [(5, 0.0, 0.0), (5, 0.0, 0.0), (5, 0.0, 0.0), (5, 0.0, 0.0), (5, 0.0, 0.0), (4, 0.0, 0.0), (5, 0.0, 0.0), (4, 0.0, 0.0), (4, 0.0, 0.0), (4, 0.0, 0.0)]\n"
          ]
        }
      ],
      "source": [
        "num_models = 10\n",
        "train_iterations = 3000\n",
        "max_size = 5\n",
        "zero_cost_warmup = 10\n",
        "\n",
        "env = gym.make('Freeway-v4')\n",
        "RS = RandomSearch(env, max_size=max_size)\n",
        "RS.search(max_models=num_models, zero_cost_warmup=zero_cost_warmup, train_iterations=train_iterations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1AFtyyi_9za",
        "outputId": "371b8f14-acb5-4dba-9cc8-654a8739a8ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64, 64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([32, 32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "model  5  trained:\n",
            "train reward:  0.0\n",
            "val reward:  0.01\n",
            "\n",
            "\n",
            "model  5  trained:\n",
            "train reward:  0.0\n",
            "val reward:  0.0\n",
            "\n",
            "\n",
            "model  5  trained:\n",
            "train reward:  0.0\n",
            "val reward:  0.0\n",
            "\n",
            "\n",
            "model  5  trained:\n",
            "train reward:  0.0\n",
            "val reward:  0.0\n",
            "\n",
            "\n",
            "model  5  trained:\n",
            "train reward:  0.0\n",
            "val reward:  0.0\n",
            "\n",
            "\n",
            "model  5  trained:\n",
            "train reward:  0.0\n",
            "val reward:  0.0\n",
            "\n",
            "\n",
            "model  5  trained:\n",
            "train reward:  0.0\n",
            "val reward:  0.0\n",
            "\n",
            "\n",
            "model  5  trained:\n",
            "train reward:  0.0\n",
            "val reward:  0.0\n",
            "\n",
            "\n",
            "model  5  trained:\n",
            "train reward:  0.006333333333333333\n",
            "val reward:  0.0\n",
            "\n",
            "\n",
            "model  5  trained:\n",
            "train reward:  0.0\n",
            "val reward:  0.0\n",
            "pool:  []\n",
            "zero cost pool:  [(5, 0.0, 0.01), (5, 0.0, 0.0), (5, 0.0, 0.0), (5, 0.0, 0.0), (5, 0.0, 0.0), (5, 0.0, 0.0), (5, 0.0, 0.0), (5, 0.0, 0.0), (5, 0.006333333333333333, 0.0), (5, 0.0, 0.0)]\n"
          ]
        }
      ],
      "source": [
        "num_models = 5\n",
        "train_iterations = 3000\n",
        "max_size = 6\n",
        "min_size = 4\n",
        "zero_cost_warmup = 10\n",
        "\n",
        "env = gym.make('Freeway-v4')\n",
        "RS = RandomSearch(env, max_model_size=max_size, min_model_size=min_size)\n",
        "RS.search(max_models=num_models, zero_cost_warmup=zero_cost_warmup, train_iterations=train_iterations)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
